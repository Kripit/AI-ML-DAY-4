{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62faebc1",
   "metadata": {},
   "source": [
    "# 🍽️ YOLOv8 - Food Classification (Using Our First Pretrained Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7227a",
   "metadata": {},
   "source": [
    "**YOLOv8** is an advanced CNN-based model used for object detection and classification.  \n",
    "We'll use its **classification head** (`yolov8n-cls.pt`), pretrained on ImageNet,  \n",
    "to fine-tune on a **subset of the Food-101 dataset** with 5 classes for high-speed, high-accuracy food recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2841d75",
   "metadata": {},
   "source": [
    "### 🎯 Goal  \n",
    "Build a production-grade food classification system using YOLOv8’s classification head.  \n",
    "We’ll fine-tune it on the following **5 food classes**:\n",
    "- pizza  \n",
    "- grilled_chicken  \n",
    "- sushi  \n",
    "- ice_cream  \n",
    "- hamburger  \n",
    "\n",
    "We'll use **advanced training techniques** to boost performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52f5586",
   "metadata": {},
   "source": [
    "### ⚙️ Techniques Used  \n",
    "- **Albumentations**: Advanced image augmentation for better generalization  \n",
    "- **Cosine Annealing LR**: Smooth learning rate decay  \n",
    "- **Model Ensembling** *(optional)*: Combines predictions for higher accuracy  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8e5cd2",
   "metadata": {},
   "source": [
    "### 📁 Directory Structure  \n",
    "```\n",
    "📦 Project Root\n",
    "├── Food_Classification_YOLOv8_Module12.ipynb\n",
    "├── generate_yaml.py\n",
    "├── food-101/\n",
    "│   ├── images/\n",
    "│   │   ├── pizza/\n",
    "│   │   ├── grilled_chicken/\n",
    "│   │   ├── sushi/\n",
    "│   │   ├── ice_cream/\n",
    "│   │   ├── hamburger/\n",
    "│   ├── meta/\n",
    "│   └── food101.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a87bd97",
   "metadata": {},
   "source": [
    "### 📦 Install Requirements  \n",
    "Make sure to install all dependencies before running the code:\n",
    "```bash\n",
    "pip install torch==2.4.1 torchvision==0.19.1\n",
    "pip install opencv-python-headless==4.10.0\n",
    "pip install ultralytics==8.2.28\n",
    "pip install albumentations==1.4.8\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8cf1b7",
   "metadata": {},
   "source": [
    "### 🔧 Basic Setup (with PyTorch + YOLOv8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8922cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I generally use PyTorch so I can understand exactly what’s happening\n",
    "\n",
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from typing import List, Dict, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a4bc61",
   "metadata": {},
   "source": [
    "* Logging to track executions and show some outputs in logs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08b7efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging setup  to track executions and errors\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "                    handlers = [\n",
    "                        logging.StreamHandler(), #to show logs in console \n",
    "                        logging.FileHandler('yolo_training.log') # save logs to a file\n",
    "                    ])\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb499f79",
   "metadata": {},
   "source": [
    "# basic config for any project \n",
    "Config Class - stores the project setting.\n",
    "\n",
    "\n",
    "* data_dir: ./food-101 dataset ka path.\n",
    "\n",
    "\n",
    "\n",
    "* classes: 5 classes ki list.\n",
    "\n",
    "\n",
    "\n",
    "* max_images_per_class: 100 images per class for training.\n",
    "\n",
    "\n",
    "\n",
    "* test_images_per_class: 20 images per class for testing.\n",
    "\n",
    "\n",
    "\n",
    "* epochs, batch_size, img_size: Training parameters.\n",
    "\n",
    "\n",
    "\n",
    "* model_path_nano, model_path_small: Nano aur small models ke save paths.\n",
    "\n",
    "\n",
    "\n",
    "* yaml_path: YAML file ka path.\n",
    "\n",
    "\n",
    "\n",
    "* device: GPU ya CPU.\n",
    "\n",
    "\n",
    "\n",
    "* lr: Initial learning rate for Cosine Annealing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184efd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations class for project settings\n",
    "\n",
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.data_dir = \"./foof/food-101\"\n",
    "        self.classes = ['pizza','grilled_chicken','sushi','ice_cream','hamburger']\n",
    "        self.max_images_per_class = 100\n",
    "        self.test_images_per_class = 20\n",
    "        self.epochs = 18\n",
    "        self.batch_size = 5 # batch size optimized for gpu \n",
    "        self.img_size = 224 # image size for yolo v8 \n",
    "        self.mode_path_nano = \"yolov8n_food_classifier.pt\" #nano model save path \n",
    "        self.model_path_small = \"yolov8s_food_classifier.pt\" #small model save path \n",
    "        self.yaml_path = os.path.join(self.data_dir, 'food101.yaml')\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.lr = 0.001\n",
    "        logging.info(f\"Using device : {self.device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc183c7",
   "metadata": {},
   "source": [
    "# * Custom dataset class to load f101 dataset \n",
    "\n",
    "* FoodDataset Class\n",
    "\n",
    " What is it?:  \n",
    " A custom dataset class built to load images and labels from the Food-101 dataset.\n",
    "\n",
    " * Key Functions:\n",
    "\n",
    "1. \"__init__\":  \n",
    " Initializes image paths, labels, and sets up image transformations using Albumentations.\n",
    "\n",
    " 2. \"__len__\":  \n",
    " Returns the total number of images in the dataset.\n",
    "\n",
    " 3. \"__getitem__\":  \n",
    " Loads an image using cv2, converts it to RGB format, applies transformations, and returns the image along with its label.\n",
    "\n",
    " * Error Handling:  \n",
    " If any image fails to load (e.g., file not found), it logs the error and returns None instead of crashing the program.\n",
    "\n",
    " * Why is it Different?:  \n",
    " Uses Albumentations instead of traditional torchvision transforms — it's more powerful and widely used in real-world, production-level image pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FoodDataset(Dataset):\n",
    "    def __init__(self, image_paths: List[str] , labels: List[int] , transform: Optional[A.Compose]=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels  # list of labels from 0 to 4 obviously but comment keep us in touch so it is important to write comments\n",
    "        self.transform = transform #albumentations transform\n",
    "        logger.info(f\"Initialized dataset with {len(image_paths)} images \")\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.image_paths)  #count of total images \n",
    "    \n",
    "    \n",
    "    def __getitem__(self , idx: int) -> Tuple[Optional[torch.Tensor], Optional[int]]: # Returns a single data sample (image tensor and label) for the given index\n",
    "        try: \n",
    "            image_path = self.image_paths[idx]\n",
    "            image = cv2.imread(image_path) # load the image\n",
    "            if image is None:\n",
    "                raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "            image = cv2.cvtColor(image , cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            if self.transform:\n",
    "                augmented = self.transform(image=image)\n",
    "                image =  augmented['image'] # Apply image transformations (e.g., resize, normalize, flip) if defined\n",
    "            label = self.labels[idx] # fetching the label ( class label )\n",
    "            return image,label \n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading image {image_path}: {str(e)}\")\n",
    "            return None , None \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ba4f5",
   "metadata": {},
   "source": [
    "#🔧 Advanced Image Preprocessing using Albumentations\n",
    "\n",
    "What is it?\n",
    "An advanced image preprocessing pipeline built using the Albumentations library for better augmentation and model robustness.\n",
    "\n",
    "# * Pipeline Explanation:\n",
    "\n",
    "1. A.Resize – Resizes the image to 224x224.\n",
    "\n",
    "2. A.HorizontalFlip – Flips the image horizontally with a 50% probability.\n",
    "\n",
    "3. A.Rotate – Randomly rotates the image by ±15 degrees.\n",
    "\n",
    "4. A.RandomBrightnessContrast – Randomly adjusts brightness and contrast.\n",
    "\n",
    "5. A.GaussNoise – Adds Gaussian noise to make the model robust to noisy inputs.\n",
    "\n",
    "6. A.MotionBlur – Adds motion blur to simulate real-world camera shake or object movement.\n",
    "\n",
    "7. A.Normalize – Normalizes the image using ImageNet mean and std.\n",
    "\n",
    "8. ToTensorV2 – Converts the image to a PyTorch tensor.\n",
    "\n",
    "* Why is it advanced?\n",
    "Albumentations provides more powerful and diverse augmentations than torchvision.transforms, enabling your model to generalize better in complex scenarios.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc3aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.Resize(224,224),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.Rotate(limit = 15 , p=0.5)  ,# randomly rotate by 15 degrees\n",
    "    A.RandomBrightnessContrast(brightness_limit = 0.2 , contrast_limit=0.2 , p =0.5),\n",
    "    A.GaussNoise(var_limit = (10.0,50.0), p =0.3) ,\n",
    "    A.MotionBlur(blur_limit=7, p =0.3),\n",
    "    A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.2225]),  # imagenet normalization \n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e632a7a",
   "metadata": {},
   "source": [
    "# 🔹 load_food101_subset Function\n",
    "📌 What is it?\n",
    "Creates a subset of the Food-101 dataset containing 5 specific classes.\n",
    "\n",
    "\n",
    "* datasets.Food101\n",
    "\n",
    "Loads the train and test splits.\n",
    "\n",
    "download=False assumes dataset is already available.\n",
    "\n",
    "class_to_idx\n",
    "\n",
    "Maps the selected class names to their corresponding label indices.\n",
    "\n",
    "train_image_paths, test_image_paths\n",
    "\n",
    "Collects a total of:\n",
    "\n",
    "500 train images → 100 per class\n",
    "\n",
    "100 test images → 20 per class\n",
    "\n",
    "Stores both image paths and labels.\n",
    "\n",
    "FoodDataset\n",
    "\n",
    "Creates custom dataset objects with Albumentations transforms applied.\n",
    "\n",
    "class_names\n",
    "\n",
    "Remaps original class labels to 0-4 for cleaner model training.\n",
    "\n",
    "Exception Handling\n",
    "\n",
    "Logs an error message if dataset loading fails (clean failover)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaac3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# food-101 dataset load and subset function\n",
    "\n",
    "def load_food101_subset(config: Config) -> Tuple[Optional[Dataset], Optional[Dataset], Optional[Dict[int, str]]]:\n",
    "    try:\n",
    "        logger.info(\"Loading food-101 dataset\")\n",
    "        \n",
    "        train_dataset = datasets.Food101(root=config.data_dir, split=\"train\", download=False)\n",
    "        test_dataset = datasets.Food101(root=config.data_dir, split=\"test\", download=False)\n",
    "\n",
    "        # Filtering Classes (we selected only 5 classes)\n",
    "        class_to_idx = {name: idx for idx, name in enumerate(train_dataset.classes) if name in config.classes}\n",
    "        \n",
    "        if len(class_to_idx) != len(config.classes):\n",
    "            raise ValueError(f\"Some classes not found in dataset: {config.classes}\")\n",
    "\n",
    "        train_image_paths = []\n",
    "        train_labels = []\n",
    "        test_image_paths = []\n",
    "        test_labels = []\n",
    "        \n",
    "        # collecting image path and labels for training set\n",
    "        \n",
    "        class_counts = {cls: 0 for cls in config.classes}\n",
    "        for idx ,(image_path , label) in enumerate(train_dataset):\n",
    "            class_name = train_dataset.classes[label]\n",
    "            if class_name in config.classes and class_counts[class_name] < config.max_images_per_class:\n",
    "                train_image_paths.append(image_path)\n",
    "                train_labels.append(config.classes.index(class_name))\n",
    "                class_counts[class_name] += 1\n",
    "                if sum(class_counts.values()) >= config.max_images_per_class * len(config.classes):\n",
    "                    break\n",
    "                \n",
    "        # now apply same for test\n",
    "        \n",
    "        class_counts = {cls: 0 for cls in config.classes}\n",
    "        for idx , (image_path , label) in enumerate(test_dataset):\n",
    "            class_name = test_dataset.classes[label]\n",
    "            if class_name in config.classes and class_counts[class_name]< config.test_images_per_class:\n",
    "                test_image_paths.append(image_path)\n",
    "                test_labels.append(config.classes.index(class_name))\n",
    "                class_counts[class_name]+=1\n",
    "                if sum(class_counts.values())>= config.test_images_per_class * len(config.classes):\n",
    "                    break\n",
    "                \n",
    "        train_subset = FoodDataset(train_image_paths , train_labels , transform)\n",
    "        test_subset = FoodDataset(test_image_paths, test_labels, transform)\n",
    "        \n",
    "        class_names = {i: cls for  i , cls in enumerate(config.classes)}\n",
    "        logger.info(f\"Loaded {len(train_image_paths)} train and {len(test_image_paths)} test images\")\n",
    "    \n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"error loading Food-101 dataset: {str(e)}\")\n",
    "        return None , None , None \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53795a98",
   "metadata": {},
   "source": [
    " # ✅ validate_model Function\n",
    "What does it do?\n",
    "Evaluates the model’s accuracy on the test set to make sure it's not just vibing but actually performing.\n",
    "\n",
    "- 🧠 How it works\n",
    "1. model.eval() puts the model into evaluation mode — shuts off dropout and other train-time tricks.\n",
    "\n",
    "2. torch.no_grad() disables gradient tracking — saves memory and speeds things up during inference.\n",
    "\n",
    "3. It loops through the test data, runs predictions using YOLOv8, and compares them with true labels.\n",
    "\n",
    "4. Uses torch.tensor([r.probs.top1 for r in results]) to handle batch predictions correctly.\n",
    "\n",
    "5. Includes basic exception handling to log errors without crashing the process.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6826d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model: YOLO , dataloader: DataLoader , class_names:Dict[int , str], config: Config) -> float:\n",
    "    try:\n",
    "        logger.info(\"Starting Validating mogger, TIME TO SEE THE FIRE SHI I BUILT LESS GO BUD \")\n",
    "        model.eval()  # model is in evaluation mode\n",
    "        correct = 0 \n",
    "        total = 0\n",
    "        with torch.no_grad(): #disable graadient \n",
    "            for images, labels in dataloader:\n",
    "                if images is None or labels is None:\n",
    "                    continue\n",
    "                images, labels = images.to(config.device), labels.to(config.device)\n",
    "                results = model(images) # YOLOv8 predictions\n",
    "                \n",
    "                predicted = torch.tensor([r.probs.top1 for r in results])\n",
    "    # top predictions images\n",
    "                total+= labels.size(0)\n",
    "                correct+= (predicted == labels).sum().item()\n",
    "        accuracy = 100 * correct / total if total>0 else 0\n",
    "        logger.info(f\"Validations accuracy : {accuracy:.2f}%\")\n",
    "        return accuracy\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in validation : {str(e)}\")\n",
    "        return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94024058",
   "metadata": {},
   "source": [
    "# Now training function which is easy to understand ### 📦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c68a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_yolo_model(config: Config , train_dataset: Dataset , test_dataset: Dataset) -> Tuple[Optional[YOLO], Optional[YOLO]]:\n",
    "    try:\n",
    "        logger.info(\"Setting up YOLOv8 models (nano and samll)\")\n",
    "        \n",
    "        \n",
    "        model_nano = YOLO('yolov8n-cls.pt')\n",
    "        model_small = YOLO('yolov8s-cls.pt')\n",
    "\n",
    "\n",
    "    # ensure YAML file exists\n",
    "        if not os.path.exists(config.yaml_path):\n",
    "            raise FileNotFoundError(f\"YAML file not found as {config.yaml_path}, Run generate_yaml.py first\")\n",
    "    \n",
    "    \n",
    "    # Making DataLoader\n",
    "    \n",
    "        train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size = config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=2,\n",
    "        pin_memory = True\n",
    "        )  \n",
    "        test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = config.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers = 2,\n",
    "        pin_memory = True\n",
    "        )\n",
    "    \n",
    "    # train nano model \n",
    "    \n",
    "        logger.info(\"Starting YOLOv8 nano training\")\n",
    "        model_nano.train(\n",
    "        data=config.yaml_path,\n",
    "        epochs =config.epochs,\n",
    "        batch = config.batch_size,\n",
    "        imgsz=config.img_size,\n",
    "        device=config.device,\n",
    "        patience = 5,\n",
    "        augment = True,\n",
    "        save = True,\n",
    "        project = \"runs/train\",\n",
    "        name=\"food_classifier_nano\",\n",
    "        optimizer='SGD',\n",
    "        lr0 = config.lr,\n",
    "        cos_lr=True # Cosine Annealing LR \n",
    "        )\n",
    "        logger.info(\"Starting YOLOv9 small training\")\n",
    "        model_small.train(\n",
    "        data=config.yaml_path,\n",
    "        epochs =config.epochs,\n",
    "        batch = config.batch_size,\n",
    "        imgsz=config.img_size,\n",
    "        device=config.device,\n",
    "        patience = 5,\n",
    "        augment = True,\n",
    "        save = True,\n",
    "        project = \"runs/train\",\n",
    "        name=\"food_classifier_small\",\n",
    "        optimizer='SGD',\n",
    "        lr0 = config.lr,\n",
    "        cos_lr=True # Cosine Annealing LR \n",
    "        )\n",
    "    \n",
    "    \n",
    "    # validate both models\n",
    "    \n",
    "        nano_accuracy = validate_model(model_nano ,test_loader , config.classes , config)\n",
    "        small_accuracy = validate_model(model_small , test_loader,config.classes, config)\n",
    "    \n",
    "        logger.info(f\"Nano model validation accuracy: {nano_accuracy:.2f}%\")\n",
    "        logger.info(f\"Small model validation accuracy: {small_accuracy:.2f}%\")\n",
    "    \n",
    "        model_nano.save(config.model_path_nano)\n",
    "        model_small.save(config.model_path_small)\n",
    "    \n",
    "        logger.info(f\"Nano model saved at {config.model_path_nano}\")\n",
    "        logger.info(f\"Nano model saved at {config.model_path_nano}\")\n",
    "        \n",
    "        return model_nano , model_small\n",
    "    except Exception as e:\n",
    "        \n",
    "        logger.error(f\"Error training YOLOv8: {str(e)}\")\n",
    "        return None , None\n",
    "    \n",
    "    \n",
    "# Ensemble prediction function\n",
    "def ensemble_predict(models: List[YOLO], image: torch.Tensor, class_names: Dict[int, str], config: Config) -> Optional[str]:\n",
    "    try:\n",
    "        logger.info(\"Starting ensemble prediction\")\n",
    "        probs = []\n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                results = model(image)\n",
    "                probs.append(results[0].probs.data.cpu().numpy())  # Probabilities for all classes\n",
    "        # Average probabilities\n",
    "        avg_probs = np.mean(probs, axis=0)\n",
    "        predicted_idx = np.argmax(avg_probs)  # Top prediction index\n",
    "        confidence = avg_probs[predicted_idx]\n",
    "        logger.info(f\"Ensemble prediction: {class_names[predicted_idx]} (Confidence: {confidence:.2f})\")\n",
    "        return class_names[predicted_idx]\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in ensemble prediction: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Inference function for single image\n",
    "def classify_image(models: List[YOLO], image_path: str, transform: A.Compose, class_names: Dict[int, str], config: Config) -> Optional[str]:\n",
    "    try:\n",
    "        logger.info(f\"Classifying image: {image_path}\")\n",
    "        image = cv2.imread(image_path)  # Image load karo\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR se RGB\n",
    "        augmented = transform(image=image)\n",
    "        image_tensor = augmented['image'].unsqueeze(0).to(config.device)  # Transform aur batch dimension\n",
    "        prediction = ensemble_predict(models, image_tensor, class_names, config)\n",
    "        return prediction\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error classifying image: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize configuration\n",
    "    config = Config()\n",
    "\n",
    "    # Check if YAML file exists\n",
    "    if not os.path.exists(config.yaml_path):\n",
    "        logger.error(f\"YAML file not found at {config.yaml_path}. Run generate_yaml.py first.\")\n",
    "        exit()\n",
    "\n",
    "    # Load dataset\n",
    "    train_dataset, test_dataset, class_names = load_food101_subset(config)\n",
    "    if train_dataset is None or test_dataset is None:\n",
    "        logger.error(\"Failed to load dataset\")\n",
    "        exit()\n",
    "\n",
    "    # Train and validate models\n",
    "    model_nano, model_small = train_yolo_model(config, train_dataset, test_dataset)\n",
    "    if model_nano is None or model_small is None:\n",
    "        logger.error(\"Failed to train models\")\n",
    "        exit()\n",
    "\n",
    "    # Test inference with ensemble\n",
    "    test_image = \"./food-101/images/pizza/1001116.jpg\"\n",
    "    prediction = classify_image([model_nano, model_small], test_image, transform, class_names, config)\n",
    "    print(f\"Predicted class: {prediction}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
